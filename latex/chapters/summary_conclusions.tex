\chapter{Summary and Conclusions}
Several methods for linear regression found in literature \cite{tibshirani1996regression,zou2005regularization,li2008network,li2010variable,pan2010incorporating,luo2012two,kim2013network}, some of which using prior knowledge in the form of a network of predictor relationships, have been studied and implemented. The various approaches perform regression by minimizing different objective functions, but in the context of this research they share common input data.

Synthetic datasets have been generated following a procedure similar to that of \cite{li2008network}. They are designed to resemble real epigenetic datasets while also providing ground truth about the relationships between their predictors and the target variable.

A method for merging of coefficient estimates in the context of multiple regression methods operating on common input data has been developed. The proposed composite voting regression uses the estimates of its underlying ensemble of regression methods to determine whether each of the predictors is related to the target variable. Each regression method "votes" for the importance of a predictor if its estimate of the predictor's coefficient is non-zero. The subset of selected predictors are those which achieve a fraction of votes greater than or equal to a certain threshold. Ordinary least squares estimation is then performed only using the set of selected variables.

We have developed a novel method of hyperparameter tuning which performs simultaneous cooperative tuning on an ensemble of regression methods. It uses an iterative process which aims to increase the similarity between coefficient estimates produced by the various methods. Our tuning method introduces cooperation between otherwise completely independent methods. This is done to reduce their individual overfitting, as well as promote agreement between their coefficient estimates. The performance of the proposed orchestrated hyperparameter tuning method depends on multiple factors, including the choice of regression methods in the ensemble, their individual hyperparameter search grids and the initial starting points of the tuning process. A number of possible modifications to the basic orchestrated tuning approach are proposed and discussed.

Both the traditional and proposed approaches to hyperparameter tuning have been used on the synthetic datasets. The performance of the various regression methods, as well as the two parameter tuning approaches has been evaluated and compared. The metrics considered include both prediction error and variable selection capabilities. Similarity between the coefficient estimates of the different methods is also evaluated and discussed. Optimal hyperparameter combinations for use on a real dataset have been chosen for each regression method based on the distributions of tuning outcomes.

Gene methylation and expression data from breast cancer patients is used to explore how the expression level of each gene is affected by the methylation levels of other genes. A subset of the regression methods is used to model these relationships and produce mappings, capable of estimating the vector of gene expression levels given a vector of gene methylation levels.

Future work:
evaluate orchestrated tuning modifications
change gene network for real data
compare mappings from prom and body regions