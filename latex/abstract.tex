\newpage
{\Huge \bf Abstract}
\vspace{24pt} 

Computational biology often involves working with high-dimensional data. Penalized regression methods are often used on such data, as they can effectively perform feature selection. Several approaches for network-constrained regression have been suggested in literature over the recent years. They use prior knowledge in the form of a network to exploit known relationships between predictors. Synthetic datasets have been generated to do parameter tuning for the various implemented methods. 

We suggest an approach for cooperative parameter tuning in the context of multiple alternative methods that share common input and goals. The aim is to tune the different regression methods iteratively, in a way that increases agreement between their coefficients. Neighboring values on the tuning parameter grid are considered for each method and iteration, selecting the set of values that achieves largest correlation with the averaged coefficients of all other methods for the previous iteration. Given enough iterations and granularity of the tuning grids, this process converges.

We also implement a simple approach to aggregate the coefficients produced by the various regression methods. Each predictor is considered relevant if it corresponds to a non-zero coefficient in a certain fraction of the underlying methods. Once a consensus has been reached through this form of voting, simple linear regression is used to fit only the relevant predictors to the data.

The common way of parameter tuning by minimization of the prediction mean squared error is implemented alongside our suggested approach. The comparison is discussed and a set of tuning parameters is assembled for use on real data. Gene methylation and expression data has been processed with the implemented algorithms. A mapping is created that shows methylation of which genes affects the expression levels of each gene.

\newpage
\vspace*{\fill}
